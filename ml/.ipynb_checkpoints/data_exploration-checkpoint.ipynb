{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ideia inicial\n",
    "\n",
    "Será feita um regressão de probabilidade de vitoria do piloto. Assim, vamos dar uma probabilidade de vitoria para os 10 primeiros colocados de 100% a 0%, para o primeiro ao ultimo colocado, respectivamente.\n",
    "- Os dados serão agregados por driver_standings.\n",
    "- Serão criados 3 modelos um para antes da corrida, outro apos as qualificações e outro durante a corrida.\n",
    "    - Antes: só vai levar em considerações os dados da pista e do piloto.\n",
    "    - Qualificação: vai levar em consideração os dados da pista, do piloto e da qualificação(tempos de volta).\n",
    "    - Corrida: vai levar em consideração os dados da pista, do piloto, da qualificação e da corrida(melhor volta, voltas lideradas, pit stops, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "class EvaluatedClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifier, cv=10, graphic=False, compact=False, is_regression=False):\n",
    "        self.classifier = classifier\n",
    "        self.cv = cv\n",
    "        self.graphic = graphic\n",
    "        self.compact = compact\n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        self.classifier.fit(X, y, *args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "    def save(self, path):\n",
    "        pickle.dump(self, open(path, 'wb'))\n",
    "\n",
    "    def fit_predict_cv(self, X, y, show_result=True):\n",
    "        res = self._cross_validate(X, y, show_result=show_result)\n",
    "        self.fit(X, y)\n",
    "        return res\n",
    "\n",
    "    def _cross_validate(self, X, y, show_result=True):\n",
    "        classification = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "        regression = ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'explained_variance',\n",
    "                      'neg_median_absolute_error']\n",
    "        scoring = classification if not self.is_regression else regression\n",
    "\n",
    "        result = cross_validate(self.classifier, X, y,\n",
    "                                scoring=scoring, n_jobs=-1)\n",
    "        if show_result:\n",
    "            print(f\"> Validação Cruzada (cv={self.cv}):\")\n",
    "            if self.is_regression:\n",
    "                print(\n",
    "                    f\"R2: {result['test_r2'].mean():.3f} (+/- {result['test_r2'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"MAE: {-result['test_neg_mean_absolute_error'].mean():.3f} (+/- {result['test_neg_mean_absolute_error'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"MSE: {-result['test_neg_mean_squared_error'].mean():.3f} (+/- {result['test_neg_mean_squared_error'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Explained Variance: {result['test_explained_variance'].mean():.3f} (+/- {result['test_explained_variance'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Median Absolute Error: {-result['test_neg_median_absolute_error'].mean():.3f} (+/- {result['test_neg_median_absolute_error'].std() * 2:.3f})\"\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Accuracy: {result['test_accuracy'].mean():.3f} (+/- {result['test_accuracy'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Precision: {result['test_precision'].mean():.3f} (+/- {result['test_precision'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Recall: {result['test_recall'].mean():.3f} (+/- {result['test_recall'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"F1: {result['test_f1'].mean():.3f} (+/- {result['test_f1'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"ROC AUC: {result['test_roc_auc'].mean():.3f} (+/- {result['test_roc_auc'].std() * 2:.3f})\"\n",
    "                )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "path = '../data/ergast/'\n",
    "circuits = pd.read_csv(path + 'circuits.csv')\n",
    "constructor_results = pd.read_csv(path + 'constructor_results.csv')\n",
    "constructor_standings = pd.read_csv(path + 'constructor_standings.csv')\n",
    "constructors = pd.read_csv(path + 'constructors.csv')\n",
    "driver_standings = pd.read_csv(path + 'driver_standings.csv')\n",
    "drivers = pd.read_csv(path + 'drivers.csv')\n",
    "lap_times = pd.read_csv(path + 'lap_times.csv')\n",
    "pit_stops = pd.read_csv(path + 'pit_stops.csv')\n",
    "qualifying = pd.read_csv(path + 'qualifying.csv')\n",
    "races = pd.read_csv(path + 'races.csv')\n",
    "results = pd.read_csv(path + 'results.csv')\n",
    "seasons = pd.read_csv(path + 'seasons.csv')\n",
    "sprint_results = pd.read_csv(path + 'sprint_results.csv')\n",
    "status = pd.read_csv(path + 'status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(results, drivers, on='driverId', suffixes=(\"\", \"_drivers\"))\n",
    "df = pd.merge(df, races, on='raceId', suffixes=(\"\", \"_races\"))\n",
    "df = pd.merge(df, circuits, on='circuitId', suffixes=(\"\", \"_circuits\"))\n",
    "df = pd.merge(df, constructors, on='constructorId', suffixes=(\"\", \"_constructors\"))\n",
    "df = pd.merge(df, status, on='statusId')\n",
    "df = pd.merge(df, driver_standings, on=['raceId', 'driverId'], suffixes=(\"\", \"_acc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/partial/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_laps = pd.merge(lap_times, races, on=\"raceId\", suffixes=(\"\", \"_race\"))\n",
    "df_laps = pd.merge(df_laps, circuits, on=\"circuitId\", suffixes=(\"\", \"_circuits\"))\n",
    "df_laps['date'] = pd.to_datetime(df_laps['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Calculate age compare to date\n",
    "df['age'] = (df['date'] - df['dob']).dt.days / 365\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "# set nulll where \\N\n",
    "df = df.replace('\\\\N', numpy.nan)\n",
    "\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "df = df.merge(weather, on=['raceId'])\n",
    "\n",
    "# round to 2 decimal humidity and temperature\n",
    "df['humidity'] = df['humidity'].round(2)\n",
    "df['temperature'] = df['temperature'].round(2)\n",
    "\n",
    "\n",
    "# based on table lap_times find the best milliseconds, that a reace made on a circuit, before a specificy race\n",
    "def best_lap_time(raceId, circuitId, race_date):\n",
    "    return df_laps[\n",
    "        (df_laps['raceId'] < raceId) & (df_laps['circuitId'] == circuitId) & (df_laps['date'] < race_date)][\n",
    "        'milliseconds'].min()\n",
    "\n",
    "\n",
    "def get_best_lap_time(row):\n",
    "    return best_lap_time(row['raceId'], row['circuitId'], row['date'])\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    df['faster_lap_circuit_ever'] = list(executor.map(get_best_lap_time, df.to_dict('records')))\n",
    "\n",
    "# Convert 'grid' and 'position' column to numeric\n",
    "df['grid'] = pd.to_numeric(df['grid'], errors='coerce')\n",
    "df['position'] = pd.to_numeric(df['position'], errors='coerce')\n",
    "\n",
    "# Ensure 'date' is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create a new dataframe with raceId, driverId, grid and position\n",
    "df_grid_position = df[['raceId', 'driverId', 'grid', 'position', 'wins']].sort_values(['driverId', 'raceId'])\n",
    "\n",
    "# Calculate the expanding mean of 'grid' and 'position' grouped by 'driverId'\n",
    "df_grid_position['AvgGrid'] = df_grid_position.groupby('driverId')['grid'].expanding().mean().reset_index(level=0,\n",
    "                                                                                                          drop=True)\n",
    "df_grid_position['AvgFn'] = df_grid_position.groupby('driverId')['position'].expanding().mean().reset_index(level=0,\n",
    "                                                                                                            drop=True)\n",
    "\n",
    "df_grid_position['wins_cum'] = df_grid_position.groupby('driverId')['wins'].expanding().sum().reset_index(level=0,\n",
    "                                                                                                          drop=True)\n",
    "\n",
    "# Merge the df_grid_position dataframe back into the main dataframe (df)\n",
    "df = pd.merge(df, df_grid_position[['raceId', 'driverId', 'AvgGrid', 'AvgFn', 'wins_cum']], on=['raceId', 'driverId'])\n",
    "\n",
    "# Ensure that AvgGrid and AvgFn are rounded to two decimal places\n",
    "df['AvgGrid'] = df['AvgGrid'].round(2)\n",
    "df['AvgFn'] = df['AvgFn'].round(2)\n",
    "df['wins_cum'] = df['wins_cum'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = [\n",
    "    'resultId',\n",
    "    'position',\n",
    "    'positionText',\n",
    "    'points',\n",
    "    'fastestLap',\n",
    "    'time',  # time to finish the race\n",
    "    'milliseconds',  # time in milisecond to finish the race\n",
    "    'fastestLapSpeed',\n",
    "    'fastestLapTime',\n",
    "    'rank',  # rank of fast lap in a race\n",
    "    'statusId',\n",
    "    'status',\n",
    "    'grid',\n",
    "\n",
    "    'raceId',\n",
    "    'year',\n",
    "    # 'date',\n",
    "    'time_races',\n",
    "    'name',  #Nome do grand pix\n",
    "    'url_races',\n",
    "\n",
    "    # 'driverId',\n",
    "    'driverRef',\n",
    "    'number_drivers',\n",
    "    'dob',\n",
    "    'code',\n",
    "    'url',\n",
    "    'forename',\n",
    "    'surname',\n",
    "\n",
    "    'driverStandingsId',\n",
    "    'number',  # car number\n",
    "    'positionText_acc',  # position acumulated unit a race\n",
    "\n",
    "    'fp1_time',\n",
    "    'fp1_date',\n",
    "    'fp2_time',\n",
    "    'fp2_date',\n",
    "    'fp3_time',\n",
    "    'fp3_date',\n",
    "\n",
    "    'quali_time',\n",
    "    'quali_date',\n",
    "    'sprint_date',\n",
    "    'sprint_time',\n",
    "\n",
    "    'constructorRef',\n",
    "    'name_constructors',\n",
    "    'url_constructors',\n",
    "\n",
    "    'circuitRef',\n",
    "    'name_circuits',\n",
    "    'location',\n",
    "    'url_circuits',\n",
    "\n",
    "    'lat',\n",
    "    'lng',\n",
    "\n",
    "    'wmo_code'\n",
    "]\n",
    "\n",
    "for col in clean:\n",
    "    if col not in df.columns:\n",
    "        print(col)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "df_clean.drop(columns=clean, inplace=True)\n",
    "\n",
    "df_clean = df_clean.rename(\n",
    "    columns={'positionOrder': 'position', 'points_acc': 'points_season', 'position_acc': 'position_season',\n",
    "             'wins': 'wins_season', 'alt': 'height', 'country': 'country_circuit'\n",
    "             })\n",
    "\n",
    "# df_clean drop null at position\n",
    "df_clean = df_clean.dropna(subset=['position'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "#\n",
    "# profile = ProfileReport(df, title='Pandas Profiling Report', )\n",
    "# profile.to_file(\"profile/final.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_prob = [i for i in range(10, 110, 10)]\n",
    "# inver position_prob\n",
    "position_prob.reverse()\n",
    "\n",
    "df_clean['position'] = df_clean.position.astype(int)\n",
    "df_clean['position'] = df_clean['position'].apply(lambda x: position_prob[x - 1] if 1 <= x <= 10 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>position</th>\n",
       "      <th>laps</th>\n",
       "      <th>nationality</th>\n",
       "      <th>round</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>date</th>\n",
       "      <th>country_circuit</th>\n",
       "      <th>height</th>\n",
       "      <th>nationality_constructors</th>\n",
       "      <th>points_season</th>\n",
       "      <th>position_season</th>\n",
       "      <th>wins_season</th>\n",
       "      <th>age</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>faster_lap_circuit_ever</th>\n",
       "      <th>AvgGrid</th>\n",
       "      <th>AvgFn</th>\n",
       "      <th>wins_cum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>British</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>British</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>dry</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.18</td>\n",
       "      <td>7.20</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>British</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>dry</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.47</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>German</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>German</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>dry</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.61</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>German</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>British</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>dry</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>58</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>French</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>dry</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25560</th>\n",
       "      <td>520</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>American</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>USA</td>\n",
       "      <td>223.0</td>\n",
       "      <td>American</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>dry</td>\n",
       "      <td>92.67</td>\n",
       "      <td>18.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.11</td>\n",
       "      <td>13.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25561</th>\n",
       "      <td>799</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>American</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>USA</td>\n",
       "      <td>223.0</td>\n",
       "      <td>American</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>dry</td>\n",
       "      <td>92.67</td>\n",
       "      <td>18.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25562</th>\n",
       "      <td>731</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>American</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>USA</td>\n",
       "      <td>223.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>dry</td>\n",
       "      <td>92.67</td>\n",
       "      <td>18.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.67</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25563</th>\n",
       "      <td>659</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>American</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>USA</td>\n",
       "      <td>223.0</td>\n",
       "      <td>American</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>dry</td>\n",
       "      <td>92.67</td>\n",
       "      <td>18.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.00</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25564</th>\n",
       "      <td>509</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>American</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>USA</td>\n",
       "      <td>223.0</td>\n",
       "      <td>American</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>dry</td>\n",
       "      <td>92.67</td>\n",
       "      <td>18.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.33</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25565 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       driverId  constructorId  position  laps nationality  round  circuitId  \\\n",
       "0             1              1       100    58     British      1          1   \n",
       "1             5              1        60    58     Finnish      1          1   \n",
       "2             2              2        90    58      German      1          1   \n",
       "3             3              3        80    58      German      1          1   \n",
       "4             4              4        70    58     Spanish      1          1   \n",
       "...         ...            ...       ...   ...         ...    ...        ...   \n",
       "25560       520            157         0   128    American      3         19   \n",
       "25561       799            113         0    52    American      3         19   \n",
       "25562       731            105         0   112    American      3         19   \n",
       "25563       659            113         0   125    American      3         19   \n",
       "25564       509            160         0   122    American      3         19   \n",
       "\n",
       "            date country_circuit  height nationality_constructors  \\\n",
       "0     2008-03-16       Australia    10.0                  British   \n",
       "1     2008-03-16       Australia    10.0                  British   \n",
       "2     2008-03-16       Australia    10.0                   German   \n",
       "3     2008-03-16       Australia    10.0                  British   \n",
       "4     2008-03-16       Australia    10.0                   French   \n",
       "...          ...             ...     ...                      ...   \n",
       "25560 1950-05-30             USA   223.0                 American   \n",
       "25561 1950-05-30             USA   223.0                 American   \n",
       "25562 1950-05-30             USA   223.0                  Italian   \n",
       "25563 1950-05-30             USA   223.0                 American   \n",
       "25564 1950-05-30             USA   223.0                 American   \n",
       "\n",
       "       points_season  position_season  wins_season  age weather_condition  \\\n",
       "0               10.0                1            1   23               dry   \n",
       "1                4.0                5            0   26               dry   \n",
       "2                8.0                2            0   30               dry   \n",
       "3                6.0                3            0   22               dry   \n",
       "4                5.0                4            0   26               dry   \n",
       "...              ...              ...          ...  ...               ...   \n",
       "25560            0.0               34            0   24               dry   \n",
       "25561            0.0               63            0   39               dry   \n",
       "25562            0.0               67            0   36               dry   \n",
       "25563            0.0               39            0   21               dry   \n",
       "25564            0.0               42            0   21               dry   \n",
       "\n",
       "       humidity  temperature  faster_lap_circuit_ever  AvgGrid  AvgFn  \\\n",
       "0         18.00        36.90                      NaN     8.18   7.20   \n",
       "1         18.00        36.90                      NaN    10.47   7.92   \n",
       "2         18.00        36.90                      NaN    11.61   9.00   \n",
       "3         18.00        36.90                      NaN     8.00   7.47   \n",
       "4         18.00        36.90                      NaN     9.00   7.87   \n",
       "...         ...          ...                      ...      ...    ...   \n",
       "25560     92.67        18.43                      NaN    17.11  13.43   \n",
       "25561     92.67        18.43                      NaN    20.00  15.00   \n",
       "25562     92.67        18.43                      NaN    16.67  12.50   \n",
       "25563     92.67        18.43                      NaN    17.00  14.50   \n",
       "25564     92.67        18.43                      NaN    17.33   8.00   \n",
       "\n",
       "       wins_cum  \n",
       "0          13.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "25560       0.0  \n",
       "25561       0.0  \n",
       "25562       0.0  \n",
       "25563       0.0  \n",
       "25564       1.0  \n",
       "\n",
       "[25565 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('../data/partial/clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_to_country = {\n",
    "    'British': 'UK',\n",
    "    'Italian': 'Italy',\n",
    "    'French': 'France',\n",
    "    'German': 'Germany',\n",
    "    'Brazilian': 'Brazil',\n",
    "    'American': 'USA',\n",
    "    'Finnish': 'Finland',  # Not in the country list, added manually\n",
    "    'Spanish': 'Spain',\n",
    "    'Australian': 'Australia',\n",
    "    'Austrian': 'Austria',\n",
    "    'Japanese': 'Japan',\n",
    "    'Belgian': 'Belgium',\n",
    "    'Swedish': 'Sweden',\n",
    "    'Swiss': 'Switzerland',\n",
    "    'Dutch': 'Netherlands',\n",
    "    'Canadian': 'Canada',\n",
    "    'Mexican': 'Mexico',\n",
    "    'New Zealander': 'New Zealand',  # Not in the country list, added manually\n",
    "    'Argentine': 'Argentina',\n",
    "    'Russian': 'Russia',\n",
    "    'South African': 'South Africa',\n",
    "    'Danish': 'Denmark',  # Not in the country list, added manually\n",
    "    'Monegasque': 'Monaco',\n",
    "    'Colombian': 'Colombia',  # Not in the country list, added manually\n",
    "    'Venezuelan': 'Venezuela',  # Not in the country list, added manually\n",
    "    'Polish': 'Poland',  # Not in the country list, added manually\n",
    "    'Irish': 'Ireland',  # Not in the country list, added manually\n",
    "    'Portuguese': 'Portugal',\n",
    "    'Thai': 'Thailand',  # Not in the country list, added manually\n",
    "    'Indian': 'India',\n",
    "    'Chilean': 'Chile',  # Not in the country list, added manually\n",
    "    'Chinese': 'China',\n",
    "    'Hungarian': 'Hungary',\n",
    "    'Rhodesian': 'Zimbabwe',  # Rhodesia is the former name of Zimbabwe\n",
    "    'Malaysian': 'Malaysia',\n",
    "    'Liechtensteiner': 'Liechtenstein',  # Not in the country list, added manually\n",
    "    'Indonesian': 'Indonesia',  # Not in the country list, added manually\n",
    "    'Uruguayan': 'Uruguay',  # Not in the country list, added manually\n",
    "    'East German': 'Germany',\n",
    "    'Czech': 'Czech Republic',  # Not in the country list, added manually\n",
    "    'American-Italian': 'USA',\n",
    "    'Argentine-Italian': 'Argentina',\n",
    "    'Hong Kong': 'Hong Kong',  # Not in the country list, added manually\n",
    "    'Bahrain': 'Bahrain',\n",
    "    'Turkey': 'Turkey',\n",
    "    'Singapore': 'Singapore',\n",
    "    'UAE': 'UAE',\n",
    "    'Korea': 'Korea',\n",
    "    'Azerbaijan': 'Azerbaijan',\n",
    "    'Morocco': 'Morocco',\n",
    "    'Qatar': 'Qatar',\n",
    "    'Saudi Arabia': 'Saudi Arabia',\n",
    "}\n",
    "\n",
    "# based on the map above create a encoder for each country\n",
    "country_encoder = [i for i in nationality_to_country.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['nationality'] = df_clean['nationality'].apply(lambda x: nationality_to_country[x])\n",
    "df_clean['nationality_constructors'] = df_clean['nationality_constructors'].apply(lambda x: nationality_to_country[x])\n",
    "\n",
    "# parse nationality, nationality_constructors and country_circuit to category\n",
    "\n",
    "df_clean['nationality'] = df_clean['nationality'].apply(lambda x: country_encoder.index(x))\n",
    "df_clean['nationality_constructors'] = df_clean['nationality_constructors'].apply(lambda x: country_encoder.index(x))\n",
    "df_clean['country_circuit'] = df_clean['country_circuit'].apply(lambda x: country_encoder.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encoder weather_conditions\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_clean['weather_condition'] = le.fit_transform(df_clean['weather_condition'])\n",
    "df_clean['weather_condition'] = df_clean['weather_condition'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driverId                             int64\n",
       "constructorId                        int64\n",
       "position                             int64\n",
       "laps                                 int64\n",
       "nationality                          int64\n",
       "round                                int64\n",
       "circuitId                            int64\n",
       "date                        datetime64[ns]\n",
       "country_circuit                      int64\n",
       "height                             float64\n",
       "nationality_constructors             int64\n",
       "points_season                      float64\n",
       "position_season                      int64\n",
       "wins_season                          int64\n",
       "age                                  int64\n",
       "weather_condition                    int64\n",
       "humidity                           float64\n",
       "temperature                        float64\n",
       "faster_lap_circuit_ever            float64\n",
       "AvgGrid                            float64\n",
       "AvgFn                              float64\n",
       "wins_cum                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['height'] = df_clean['height'].astype('float')\n",
    "# columns types\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25565 entries, 0 to 25564\n",
      "Data columns (total 22 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   driverId                  25565 non-null  int64         \n",
      " 1   constructorId             25565 non-null  int64         \n",
      " 2   position                  25565 non-null  int64         \n",
      " 3   laps                      25565 non-null  int64         \n",
      " 4   nationality               25565 non-null  int64         \n",
      " 5   round                     25565 non-null  int64         \n",
      " 6   circuitId                 25565 non-null  int64         \n",
      " 7   date                      25565 non-null  datetime64[ns]\n",
      " 8   country_circuit           25565 non-null  int64         \n",
      " 9   height                    25565 non-null  float64       \n",
      " 10  nationality_constructors  25565 non-null  int64         \n",
      " 11  points_season             25565 non-null  float64       \n",
      " 12  position_season           25565 non-null  int64         \n",
      " 13  wins_season               25565 non-null  int64         \n",
      " 14  age                       25565 non-null  int64         \n",
      " 15  weather_condition         25565 non-null  int64         \n",
      " 16  humidity                  25565 non-null  float64       \n",
      " 17  temperature               25565 non-null  float64       \n",
      " 18  faster_lap_circuit_ever   5238 non-null   float64       \n",
      " 19  AvgGrid                   25565 non-null  float64       \n",
      " 20  AvgFn                     24478 non-null  float64       \n",
      " 21  wins_cum                  25565 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(13)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T12:36:21.880673Z",
     "start_time": "2023-06-21T12:36:21.717646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove faster_lap_circuit_ever column\n",
    "df_clean = df_clean.drop(columns=['faster_lap_circuit_ever'])\n",
    "\n",
    "df_clean = df_clean.dropna(subset=['AvgFn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "driverId                    0\n",
       "constructorId               0\n",
       "position                    0\n",
       "laps                        0\n",
       "nationality                 0\n",
       "round                       0\n",
       "circuitId                   0\n",
       "date                        0\n",
       "country_circuit             0\n",
       "height                      0\n",
       "nationality_constructors    0\n",
       "points_season               0\n",
       "position_season             0\n",
       "wins_season                 0\n",
       "age                         0\n",
       "weather_condition           0\n",
       "humidity                    0\n",
       "temperature                 0\n",
       "AvgGrid                     0\n",
       "AvgFn                       0\n",
       "wins_cum                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect null values\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_clean.drop(columns=['position']), df_clean['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 778, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 180, in result_type\nTypeError: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Randon Forest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[0;32m----> 4\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluatedClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_regression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m, in \u001b[0;36mEvaluatedClassifier.fit_predict_cv\u001b[0;34m(self, X, y, show_result)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict_cv\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, show_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 29\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mEvaluatedClassifier._cross_validate\u001b[0;34m(self, X, y, show_result)\u001b[0m\n\u001b[1;32m     35\u001b[0m regression \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplained_variance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_median_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m scoring \u001b[38;5;241m=\u001b[39m classification \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_regression \u001b[38;5;28;01melse\u001b[39;00m regression\n\u001b[0;32m---> 39\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_result:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Validação Cruzada (cv=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[0;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[0;32m~/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/Users/vitor/Desktop/mestrado/eam_venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 778, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n  File \"<__array_function__ internals>\", line 180, in result_type\nTypeError: The DType <class 'numpy.dtype[datetime64]'> could not be promoted by <class 'numpy.dtype[float64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>)\n"
     ]
    }
   ],
   "source": [
    "# Randon Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "_ = EvaluatedClassifier(RandomForestRegressor(), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = EvaluatedClassifier(RandomForestRegressor(n_jobs=-1), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_eval = EvaluatedClassifier(XGBRegressor(\n",
    "    # n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    "    learning_rate=0.1,\n",
    "), is_regression=True)\n",
    "\n",
    "_ = model_eval.fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "_ = EvaluatedClassifier(MLPRegressor(\n",
    "    # hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100, 100),\n",
    "    max_iter=1000,\n",
    "    # activation='relu',\n",
    "    # solver='adam',\n",
    "    # learning_rate='adaptive',\n",
    "    learning_rate_init=0.1,\n",
    "    # alpha=0.01,\n",
    "    # batch_size=100,\n",
    "    # verbose=True,\n",
    "    # random_state=42,\n",
    "    # tol=0.0001,\n",
    "    # early_stopping=True,\n",
    "    # validation_fraction=0.1,\n",
    "    # n_iter_no_change=10,\n",
    "    # shuffle=True,\n",
    "    # warm_start=False,\n",
    "    # momentum=0.9,\n",
    "    # nesterovs_momentum=True,\n",
    "    # power_t=0.5,\n",
    "    # beta_1=0.9,\n",
    "    # beta_2=0.999,\n",
    "    # epsilon=1e-08,\n",
    "    # max_fun=15000\n",
    "), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "model_eval.save('model/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "races['date'] = pd.to_datetime(races.date)\n",
    "race_next = races.loc[races.date > datetime.now()].sort_values(by='date')\n",
    "race_next = pd.merge(race_next, circuits, on='circuitId')\n",
    "# get last row\n",
    "race_next = race_next.iloc[0]\n",
    "drivers_next = [842, 815, 4, 844, 840, 858, 825, 852, 848, 855, 807, 839, 830, 846, 1, 856, 832, 847, 822, 857]\n",
    "\n",
    "# get the drivers\n",
    "info_new = df_clean.loc[df_clean['driverId'].isin(drivers_next)].sort_values(by='date')\n",
    "\n",
    "info_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rank = {}\n",
    "for i in drivers_next:\n",
    "    try:\n",
    "        temp = info_new.loc[info_new['driverId'] == i].iloc[0]\n",
    "        temp.circuitId = race_next.circuitId\n",
    "        temp.country_circuit = country_encoder.index(race_next.country)\n",
    "        temp.height = race_next.alt\n",
    "        # rain 67.66666666666667 23.066666666666666\n",
    "        temp.weather_condition = le.transform(['rain'])[0]\n",
    "        temp.humidity = 67.67\n",
    "        temp.temperature = 23.07\n",
    "        stay = set(temp.index) - {'driverId', 'faster_lap_circuit_ever', 'date', 'position'}\n",
    "        temp.round = race_next.round\n",
    "        temp = temp[list(stay)]\n",
    "        if np.isnan(temp.AvgFn):\n",
    "            temp.AvgFn = 10.0\n",
    "\n",
    "        if i == 830:\n",
    "            temp.wins_cum = 34\n",
    "            temp.wins_season = 14\n",
    "            temp.AvgFn = 1.0\n",
    "            temp.points_season = 100\n",
    "            print(temp)\n",
    "\n",
    "        if i == 825:\n",
    "            print(temp)\n",
    "\n",
    "        df_temp = pd.DataFrame([temp], columns=temp.index)\n",
    "        # order columns to['constructorId', 'laps', 'nationality', 'round', 'circuitId', 'country_circuit', 'height', 'nationality_constructors', 'points_season', 'position_season', 'wins_season', 'age', 'weather_condition', 'humidity', 'temperature', 'AvgGrid', 'AvgFn', 'wins_cum']\n",
    "\n",
    "        df_temp = df_temp[['constructorId', 'laps', 'nationality', 'round', 'circuitId', 'country_circuit', 'height',\n",
    "                           'nationality_constructors', 'points_season', 'position_season', 'wins_season', 'age',\n",
    "                           'weather_condition', 'humidity', 'temperature', 'AvgGrid', 'AvgFn', 'wins_cum']]\n",
    "\n",
    "        rank[i] = float(model_eval.predict(df_temp)[0])\n",
    "    except:\n",
    "        print(\"Failed to predict driver: \", i)\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the rank by value\n",
    "rank = dict(sorted(rank.items(), key=lambda item: item[1]))\n",
    "\n",
    "for i in rank:\n",
    "    print(drivers.loc[drivers.driverId == i].iloc[0].forename, drivers.loc[drivers.driverId == i].iloc[0].surname,\n",
    "          rank[i])\n",
    "    rank[i] = {\n",
    "        \"name\": drivers.loc[drivers.driverId == i].iloc[0].forename + \" \" + drivers.loc[drivers.driverId == i].iloc[\n",
    "            0].surname,\n",
    "        \"rank\": rank[i]\n",
    "    }\n",
    "\n",
    "# save the rank\n",
    "import json\n",
    "\n",
    "with open('../result/rank.json', 'w') as fp:\n",
    "    json.dump(rank, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# forecast\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "    \"latitude\": race_next[\"lat\"],\n",
    "    \"longitude\": race_next[\"lng\"],\n",
    "    \"start_date\": race_next[\"date\"].strftime(\"%Y-%m-%d\"),\n",
    "    \"end_date\": race_next[\"date\"].strftime(\"%Y-%m-%d\"),\n",
    "    \"hourly\": \"relativehumidity_2m,weathercode,temperature_2m\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=params)\n",
    "print(response.url)\n",
    "data = response.json()\n",
    "\n",
    "race_next['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
