{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ideia inicial\n",
    "\n",
    "Será feita um regressão de probabilidade de vitoria do piloto. Assim, vamos dar uma probabilidade de vitoria para os 10 primeiros colocados de 100% a 0%, para o primeiro ao ultimo colocado, respectivamente.\n",
    "- Os dados serão agregados por driver_standings.\n",
    "- Serão criados 3 modelos um para antes da corrida, outro apos as qualificações e outro durante a corrida.\n",
    "    - Antes: só vai levar em considerações os dados da pista e do piloto.\n",
    "    - Qualificação: vai levar em consideração os dados da pista, do piloto e da qualificação(tempos de volta).\n",
    "    - Corrida: vai levar em consideração os dados da pista, do piloto, da qualificação e da corrida(melhor volta, voltas lideradas, pit stops, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:28:50.134689Z",
     "start_time": "2023-06-27T06:28:50.129600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "class EvaluatedClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifier, cv=10, graphic=False, compact=False, is_regression=False):\n",
    "        self.classifier = classifier\n",
    "        self.cv = cv\n",
    "        self.graphic = graphic\n",
    "        self.compact = compact\n",
    "        self.is_regression = is_regression\n",
    "\n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        self.classifier.fit(X, y, *args, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "\n",
    "    def save(self, path):\n",
    "        pickle.dump(self, open(path, 'wb'))\n",
    "\n",
    "    def fit_predict_cv(self, X, y, show_result=True):\n",
    "        res = self._cross_validate(X, y, show_result=show_result)\n",
    "        self.fit(X, y)\n",
    "        return res\n",
    "\n",
    "    def _cross_validate(self, X, y, show_result=True):\n",
    "        classification = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "        regression = ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'explained_variance',\n",
    "                      'neg_median_absolute_error']\n",
    "        scoring = classification if not self.is_regression else regression\n",
    "\n",
    "        result = cross_validate(self.classifier, X, y,\n",
    "                                scoring=scoring, n_jobs=-1)\n",
    "        if show_result:\n",
    "            print(f\"> Validação Cruzada (cv={self.cv}):\")\n",
    "            if self.is_regression:\n",
    "                print(\n",
    "                    f\"R2: {result['test_r2'].mean():.3f} (+/- {result['test_r2'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"MAE: {-result['test_neg_mean_absolute_error'].mean():.3f} (+/- {result['test_neg_mean_absolute_error'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"MSE: {-result['test_neg_mean_squared_error'].mean():.3f} (+/- {result['test_neg_mean_squared_error'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Explained Variance: {result['test_explained_variance'].mean():.3f} (+/- {result['test_explained_variance'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Median Absolute Error: {-result['test_neg_median_absolute_error'].mean():.3f} (+/- {result['test_neg_median_absolute_error'].std() * 2:.3f})\"\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Accuracy: {result['test_accuracy'].mean():.3f} (+/- {result['test_accuracy'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Precision: {result['test_precision'].mean():.3f} (+/- {result['test_precision'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"Recall: {result['test_recall'].mean():.3f} (+/- {result['test_recall'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"F1: {result['test_f1'].mean():.3f} (+/- {result['test_f1'].std() * 2:.3f})\\n\" + \\\n",
    "                    f\"ROC AUC: {result['test_roc_auc'].mean():.3f} (+/- {result['test_roc_auc'].std() * 2:.3f})\"\n",
    "                )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:48.227268Z",
     "start_time": "2023-06-27T06:53:47.943557Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "path = '../data/ergast/'\n",
    "circuits = pd.read_csv(path + 'circuits.csv')\n",
    "constructor_results = pd.read_csv(path + 'constructor_results.csv')\n",
    "constructor_standings = pd.read_csv(path + 'constructor_standings.csv')\n",
    "constructors = pd.read_csv(path + 'constructors.csv')\n",
    "driver_standings = pd.read_csv(path + 'driver_standings_update.csv')\n",
    "drivers = pd.read_csv(path + 'drivers.csv')\n",
    "lap_times = pd.read_csv(path + 'lap_times.csv')\n",
    "pit_stops = pd.read_csv(path + 'pit_stops.csv')\n",
    "qualifying = pd.read_csv(path + 'qualifying.csv')\n",
    "races = pd.read_csv(path + 'races.csv')\n",
    "results = pd.read_csv(path + 'results_update.csv')\n",
    "seasons = pd.read_csv(path + 'seasons.csv')\n",
    "sprint_results = pd.read_csv(path + 'sprint_results.csv')\n",
    "status = pd.read_csv(path + 'status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "races_shift = races.copy()\n",
    "races_shift['nextRaceId'] = races_shift['raceId'].shift(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:48.230381Z",
     "start_time": "2023-06-27T06:53:48.228765Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/2hcmsh8j13j8m0qdsc159q5w0000gn/T/ipykernel_42613/4182227770.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  driver_standings_previus = driver_standings_previus.append(driver_standings_first_round)\n"
     ]
    }
   ],
   "source": [
    "# Creating a driver_standings_previus, that going contains the previous raceId standings for a drive, if is the first of season fill points, position and wins with 0.\n",
    "races_shift = races.copy()\n",
    "races_shift['nextRaceId'] = races_shift['raceId'].shift(-1)\n",
    "\n",
    "driver_standings_previus = driver_standings.copy()\n",
    "driver_standings_previus['raceId'] = driver_standings_previus['raceId'].apply(lambda x: races_shift.loc[races_shift['raceId'] == x, 'nextRaceId'].values[0])\n",
    "\n",
    "# Create a DataFrame with zeros for points, position, and wins for the first race of each season\n",
    "driver_standings_first_round = driver_standings.loc[driver_standings['raceId'] == 1].copy()\n",
    "driver_standings_first_round[['points', 'position', 'wins']] = 0\n",
    "\n",
    "driver_standings_previus = driver_standings_previus.append(driver_standings_first_round)\n",
    "\n",
    "races_first_round = races_shift.loc[races['round'] == 1, 'raceId'].to_list()\n",
    "\n",
    "# for each raceId races_first_round, in driver_standings_previus fill fill points, position and wins with 0.\n",
    "for race_id in races_first_round:\n",
    "    driver_standings_previus.loc[driver_standings_previus['raceId'] == race_id, 'points'] = 0\n",
    "    driver_standings_previus.loc[driver_standings_previus['raceId'] == race_id, 'position'] = 0\n",
    "    driver_standings_previus.loc[driver_standings_previus['raceId'] == race_id, 'wins'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:50.532727Z",
     "start_time": "2023-06-27T06:53:48.232787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "driverStandingsId    0\nraceId               0\ndriverId             0\npoints               0\nposition             0\npositionText         0\nwins                 0\ndtype: int64"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if number of rows is the same\n",
    "driver_standings_previus.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:50.532940Z",
     "start_time": "2023-06-27T06:53:50.524061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:50.636884Z",
     "start_time": "2023-06-27T06:53:50.531704Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(results, drivers, on='driverId', suffixes=(\"\", \"_drivers\"))\n",
    "df = pd.merge(df, races, on='raceId', suffixes=(\"\", \"_races\"))\n",
    "df = pd.merge(df, circuits, on='circuitId', suffixes=(\"\", \"_circuits\"))\n",
    "df = pd.merge(df, constructors, on='constructorId', suffixes=(\"\", \"_constructors\"))\n",
    "df = pd.merge(df, status, on='statusId')\n",
    "df = pd.merge(df, driver_standings_previus, on=['raceId', 'driverId'], suffixes=(\"\", \"_acc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:50.923067Z",
     "start_time": "2023-06-27T06:53:50.637954Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/partial/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.341439Z",
     "start_time": "2023-06-27T06:53:50.924625Z"
    }
   },
   "outputs": [],
   "source": [
    "df_laps = pd.merge(lap_times, races, on=\"raceId\", suffixes=(\"\", \"_race\"))\n",
    "df_laps = pd.merge(df_laps, circuits, on=\"circuitId\", suffixes=(\"\", \"_circuits\"))\n",
    "df_laps['date'] = pd.to_datetime(df_laps['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.481803Z",
     "start_time": "2023-06-27T06:53:51.347389Z"
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# Calculate age compare to date\n",
    "df['age'] = (df['date'] - df['dob']).dt.days / 365\n",
    "df['age'] = df['age'].astype(int)\n",
    "\n",
    "# set nulll where \\N\n",
    "df = df.replace('\\\\N', numpy.nan)\n",
    "\n",
    "weather = pd.read_csv('../data/weather/weather.csv')\n",
    "df = df.merge(weather, on=['raceId'])\n",
    "\n",
    "# round to 2 decimal humidity and temperature\n",
    "df['humidity'] = df['humidity'].round(2)\n",
    "df['temperature'] = df['temperature'].round(2)\n",
    "\n",
    "# based on table lap_times find the best milliseconds, that a reace made on a circuit, before a specificy race\n",
    "# def best_lap_time(raceId, circuitId, race_date):\n",
    "#     return df_laps[\n",
    "#         (df_laps['raceId'] < raceId) & (df_laps['circuitId'] == circuitId) & (df_laps['date'] < race_date)][\n",
    "#         'milliseconds'].min()\n",
    "#\n",
    "#\n",
    "# def get_best_lap_time(row):\n",
    "#     return best_lap_time(row['raceId'], row['circuitId'], row['date'])\n",
    "#\n",
    "#\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     df['faster_lap_circuit_ever'] = list(executor.map(get_best_lap_time, df.to_dict('records')))\n",
    "\n",
    "# Convert 'grid' and 'position' column to numeric\n",
    "df['grid'] = pd.to_numeric(df['grid'], errors='coerce')\n",
    "df['position'] = pd.to_numeric(df['position'], errors='coerce')\n",
    "\n",
    "# Ensure 'date' is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create a new dataframe with raceId, driverId, grid and position\n",
    "df_grid_position = df[['raceId', 'driverId', 'grid', 'position', 'wins']].sort_values(['driverId', 'raceId'])\n",
    "\n",
    "# Calculate the expanding mean of 'grid' and 'position' grouped by 'driverId'\n",
    "df_grid_position['AvgGrid'] = df_grid_position.groupby('driverId')['grid'].expanding().mean().reset_index(level=0,\n",
    "                                                                                                          drop=True)\n",
    "df_grid_position['AvgFn'] = df_grid_position.groupby('driverId')['position'].expanding().mean().reset_index(level=0,\n",
    "                                                                                                            drop=True)\n",
    "\n",
    "df_grid_position['wins_acc'] = df_grid_position.groupby('driverId')['wins'].expanding().sum().reset_index(level=0,\n",
    "                                                                                                          drop=True)\n",
    "\n",
    "# Merge the df_grid_position dataframe back into the main dataframe (df)\n",
    "df = pd.merge(df, df_grid_position[['raceId', 'driverId', 'AvgGrid', 'AvgFn', 'wins_acc']], on=['raceId', 'driverId'])\n",
    "\n",
    "# Ensure that AvgGrid and AvgFn are rounded to two decimal places\n",
    "df['AvgGrid'] = df['AvgGrid'].round(2)\n",
    "df['AvgFn'] = df['AvgFn'].round(2)\n",
    "df['wins_acc'] = df['wins_acc'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23726 entries, 0 to 23725\n",
      "Data columns (total 69 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   resultId                  23726 non-null  int64         \n",
      " 1   raceId                    23726 non-null  int64         \n",
      " 2   driverId                  23726 non-null  int64         \n",
      " 3   constructorId             23726 non-null  int64         \n",
      " 4   number                    23724 non-null  object        \n",
      " 5   grid                      23726 non-null  int64         \n",
      " 6   position                  14186 non-null  float64       \n",
      " 7   positionText              23726 non-null  object        \n",
      " 8   positionOrder             23726 non-null  int64         \n",
      " 9   points                    23726 non-null  float64       \n",
      " 10  laps                      23726 non-null  int64         \n",
      " 11  time                      6954 non-null   object        \n",
      " 12  milliseconds              6953 non-null   object        \n",
      " 13  fastestLap                7375 non-null   object        \n",
      " 14  rank                      7578 non-null   object        \n",
      " 15  fastestLapTime            7375 non-null   object        \n",
      " 16  fastestLapSpeed           7375 non-null   object        \n",
      " 17  statusId                  23726 non-null  int64         \n",
      " 18  driverRef                 23726 non-null  object        \n",
      " 19  number_drivers            5681 non-null   object        \n",
      " 20  code                      9123 non-null   object        \n",
      " 21  forename                  23726 non-null  object        \n",
      " 22  surname                   23726 non-null  object        \n",
      " 23  dob                       23726 non-null  datetime64[ns]\n",
      " 24  nationality               23726 non-null  object        \n",
      " 25  url                       23726 non-null  object        \n",
      " 26  year                      23726 non-null  int64         \n",
      " 27  round                     23726 non-null  int64         \n",
      " 28  circuitId                 23726 non-null  int64         \n",
      " 29  name                      23726 non-null  object        \n",
      " 30  date                      23726 non-null  datetime64[ns]\n",
      " 31  time_races                7370 non-null   object        \n",
      " 32  url_races                 23726 non-null  object        \n",
      " 33  fp1_date                  1079 non-null   object        \n",
      " 34  fp1_time                  648 non-null    object        \n",
      " 35  fp2_date                  1079 non-null   object        \n",
      " 36  fp2_time                  648 non-null    object        \n",
      " 37  fp3_date                  939 non-null    object        \n",
      " 38  fp3_time                  568 non-null    object        \n",
      " 39  quali_date                1079 non-null   object        \n",
      " 40  quali_time                648 non-null    object        \n",
      " 41  sprint_date               140 non-null    object        \n",
      " 42  sprint_time               80 non-null     object        \n",
      " 43  circuitRef                23726 non-null  object        \n",
      " 44  name_circuits             23726 non-null  object        \n",
      " 45  location                  23726 non-null  object        \n",
      " 46  country                   23726 non-null  object        \n",
      " 47  lat                       23726 non-null  float64       \n",
      " 48  lng                       23726 non-null  float64       \n",
      " 49  alt                       23726 non-null  float64       \n",
      " 50  url_circuits              23726 non-null  object        \n",
      " 51  constructorRef            23726 non-null  object        \n",
      " 52  name_constructors         23726 non-null  object        \n",
      " 53  nationality_constructors  23726 non-null  object        \n",
      " 54  url_constructors          23726 non-null  object        \n",
      " 55  status                    23726 non-null  object        \n",
      " 56  driverStandingsId         23726 non-null  int64         \n",
      " 57  points_acc                23726 non-null  float64       \n",
      " 58  position_acc              23726 non-null  int64         \n",
      " 59  positionText_acc          23726 non-null  object        \n",
      " 60  wins                      23726 non-null  int64         \n",
      " 61  age                       23726 non-null  int64         \n",
      " 62  weather_condition         23726 non-null  object        \n",
      " 63  humidity                  23726 non-null  float64       \n",
      " 64  wmo_code                  23726 non-null  float64       \n",
      " 65  temperature               23726 non-null  float64       \n",
      " 66  AvgGrid                   23726 non-null  float64       \n",
      " 67  AvgFn                     22895 non-null  float64       \n",
      " 68  wins_acc                  23726 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(15), object(40)\n",
      "memory usage: 12.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.536121Z",
     "start_time": "2023-06-27T06:53:51.514987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.573001Z",
     "start_time": "2023-06-27T06:53:51.537579Z"
    }
   },
   "outputs": [],
   "source": [
    "clean = [\n",
    "    'resultId',\n",
    "    'position',\n",
    "    'positionText',\n",
    "    'points',\n",
    "    'fastestLap',\n",
    "    'time',  # time to finish the race\n",
    "    'milliseconds',  # time in milisecond to finish the race\n",
    "    'fastestLapSpeed',\n",
    "    'fastestLapTime',\n",
    "    'rank',  # rank of fast lap in a race\n",
    "    'statusId',\n",
    "    'status',\n",
    "    # 'grid',\n",
    "    # 'laps',\n",
    "\n",
    "    'raceId',\n",
    "    'year',\n",
    "    'date',\n",
    "    'time_races',\n",
    "    'name',  #Nome do grand pix\n",
    "    'url_races',\n",
    "\n",
    "    'driverId',\n",
    "    'driverRef',\n",
    "    'number_drivers',\n",
    "    'dob',\n",
    "    'code',\n",
    "    'url',\n",
    "    'forename',\n",
    "    'surname',\n",
    "\n",
    "    'driverStandingsId',\n",
    "    'number',  # car number\n",
    "    'positionText_acc',  # position acumulated unit a race\n",
    "\n",
    "    'fp1_time',\n",
    "    'fp1_date',\n",
    "    'fp2_time',\n",
    "    'fp2_date',\n",
    "    'fp3_time',\n",
    "    'fp3_date',\n",
    "\n",
    "    'quali_time',\n",
    "    'quali_date',\n",
    "    'sprint_date',\n",
    "    'sprint_time',\n",
    "\n",
    "    'constructorRef',\n",
    "    'name_constructors',\n",
    "    'url_constructors',\n",
    "\n",
    "    'circuitRef',\n",
    "    'name_circuits',\n",
    "    'location',\n",
    "    'url_circuits',\n",
    "\n",
    "    'lat',\n",
    "    'lng',\n",
    "\n",
    "    'wmo_code'\n",
    "]\n",
    "\n",
    "for col in clean:\n",
    "    if col not in df.columns:\n",
    "        print(col)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "df_clean.drop(columns=clean, inplace=True)\n",
    "\n",
    "df_clean = df_clean.rename(\n",
    "    columns={'positionOrder': 'position', 'points_acc': 'points_season', 'position_acc': 'position_season',\n",
    "             'wins': 'wins_season', 'alt': 'height', 'country': 'country_circuit'\n",
    "             })\n",
    "\n",
    "# df_clean drop null at position\n",
    "df_clean = df_clean.dropna(subset=['position'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.587486Z",
     "start_time": "2023-06-27T06:53:51.559683Z"
    }
   },
   "outputs": [],
   "source": [
    "# from ydata_profiling import ProfileReport\n",
    "#\n",
    "# profile = ProfileReport(df, title='Pandas Profiling Report', )\n",
    "# profile.to_file(\"profile/final.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.587681Z",
     "start_time": "2023-06-27T06:53:51.573128Z"
    }
   },
   "outputs": [],
   "source": [
    "position_prob = [i for i in range(10, 110, 10)]\n",
    "# inver position_prob\n",
    "position_prob.reverse()\n",
    "\n",
    "df_clean['position'] = df_clean.position.astype(int)\n",
    "df_clean['position'] = df_clean['position'].apply(lambda x: position_prob[x - 1] if 1 <= x <= 10 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.665107Z",
     "start_time": "2023-06-27T06:53:51.573349Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('../data/partial/clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.669199Z",
     "start_time": "2023-06-27T06:53:51.665825Z"
    }
   },
   "outputs": [],
   "source": [
    "nationality_to_country = {\n",
    "    'British': 'UK',\n",
    "    'Italian': 'Italy',\n",
    "    'French': 'France',\n",
    "    'German': 'Germany',\n",
    "    'Brazilian': 'Brazil',\n",
    "    'American': 'USA',\n",
    "    'Finnish': 'Finland',  # Not in the country list, added manually\n",
    "    'Spanish': 'Spain',\n",
    "    'Australian': 'Australia',\n",
    "    'Austrian': 'Austria',\n",
    "    'Japanese': 'Japan',\n",
    "    'Belgian': 'Belgium',\n",
    "    'Swedish': 'Sweden',\n",
    "    'Swiss': 'Switzerland',\n",
    "    'Dutch': 'Netherlands',\n",
    "    'Canadian': 'Canada',\n",
    "    'Mexican': 'Mexico',\n",
    "    'New Zealander': 'New Zealand',  # Not in the country list, added manually\n",
    "    'Argentine': 'Argentina',\n",
    "    'Russian': 'Russia',\n",
    "    'South African': 'South Africa',\n",
    "    'Danish': 'Denmark',  # Not in the country list, added manually\n",
    "    'Monegasque': 'Monaco',\n",
    "    'Colombian': 'Colombia',  # Not in the country list, added manually\n",
    "    'Venezuelan': 'Venezuela',  # Not in the country list, added manually\n",
    "    'Polish': 'Poland',  # Not in the country list, added manually\n",
    "    'Irish': 'Ireland',  # Not in the country list, added manually\n",
    "    'Portuguese': 'Portugal',\n",
    "    'Thai': 'Thailand',  # Not in the country list, added manually\n",
    "    'Indian': 'India',\n",
    "    'Chilean': 'Chile',  # Not in the country list, added manually\n",
    "    'Chinese': 'China',\n",
    "    'Hungarian': 'Hungary',\n",
    "    'Rhodesian': 'Zimbabwe',  # Rhodesia is the former name of Zimbabwe\n",
    "    'Malaysian': 'Malaysia',\n",
    "    'Liechtensteiner': 'Liechtenstein',  # Not in the country list, added manually\n",
    "    'Indonesian': 'Indonesia',  # Not in the country list, added manually\n",
    "    'Uruguayan': 'Uruguay',  # Not in the country list, added manually\n",
    "    'East German': 'Germany',\n",
    "    'Czech': 'Czech Republic',  # Not in the country list, added manually\n",
    "    'American-Italian': 'USA',\n",
    "    'Argentine-Italian': 'Argentina',\n",
    "    'Hong Kong': 'Hong Kong',  # Not in the country list, added manually\n",
    "    'Bahrain': 'Bahrain',\n",
    "    'Turkey': 'Turkey',\n",
    "    'Singapore': 'Singapore',\n",
    "    'UAE': 'UAE',\n",
    "    'Korea': 'Korea',\n",
    "    'Azerbaijan': 'Azerbaijan',\n",
    "    'Morocco': 'Morocco',\n",
    "    'Qatar': 'Qatar',\n",
    "    'Saudi Arabia': 'Saudi Arabia',\n",
    "}\n",
    "\n",
    "# based on the map above create a encoder for each country\n",
    "country_encoder = [i for i in nationality_to_country.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.703287Z",
     "start_time": "2023-06-27T06:53:51.674356Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean['nationality'] = df_clean['nationality'].apply(lambda x: nationality_to_country[x])\n",
    "df_clean['nationality_constructors'] = df_clean['nationality_constructors'].apply(lambda x: nationality_to_country[x])\n",
    "\n",
    "# parse nationality, nationality_constructors and country_circuit to category\n",
    "\n",
    "df_clean['nationality'] = df_clean['nationality'].apply(lambda x: country_encoder.index(x))\n",
    "df_clean['nationality_constructors'] = df_clean['nationality_constructors'].apply(lambda x: country_encoder.index(x))\n",
    "df_clean['country_circuit'] = df_clean['country_circuit'].apply(lambda x: country_encoder.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.703421Z",
     "start_time": "2023-06-27T06:53:51.695608Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encoder weather_conditions\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_clean['weather_condition'] = le.fit_transform(df_clean['weather_condition'])\n",
    "df_clean['weather_condition'] = df_clean['weather_condition'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.703559Z",
     "start_time": "2023-06-27T06:53:51.697963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "constructorId                 int64\ngrid                          int64\nposition                      int64\nlaps                          int64\nnationality                   int64\nround                         int64\ncircuitId                     int64\ncountry_circuit               int64\nheight                      float64\nnationality_constructors      int64\npoints_season               float64\nposition_season               int64\nwins_season                   int64\nage                           int64\nweather_condition             int64\nhumidity                    float64\ntemperature                 float64\nAvgGrid                     float64\nAvgFn                       float64\nwins_acc                    float64\ndtype: object"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['height'] = df_clean['height'].astype('float')\n",
    "# columns types\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.717518Z",
     "start_time": "2023-06-27T06:53:51.701886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23726 entries, 0 to 23725\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   constructorId             23726 non-null  int64  \n",
      " 1   grid                      23726 non-null  int64  \n",
      " 2   position                  23726 non-null  int64  \n",
      " 3   laps                      23726 non-null  int64  \n",
      " 4   nationality               23726 non-null  int64  \n",
      " 5   round                     23726 non-null  int64  \n",
      " 6   circuitId                 23726 non-null  int64  \n",
      " 7   country_circuit           23726 non-null  int64  \n",
      " 8   height                    23726 non-null  float64\n",
      " 9   nationality_constructors  23726 non-null  int64  \n",
      " 10  points_season             23726 non-null  float64\n",
      " 11  position_season           23726 non-null  int64  \n",
      " 12  wins_season               23726 non-null  int64  \n",
      " 13  age                       23726 non-null  int64  \n",
      " 14  weather_condition         23726 non-null  int64  \n",
      " 15  humidity                  23726 non-null  float64\n",
      " 16  temperature               23726 non-null  float64\n",
      " 17  AvgGrid                   23726 non-null  float64\n",
      " 18  AvgFn                     22895 non-null  float64\n",
      " 19  wins_acc                  23726 non-null  float64\n",
      "dtypes: float64(7), int64(13)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.717639Z",
     "start_time": "2023-06-27T06:53:51.707604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove faster_lap_circuit_ever column\n",
    "# df_clean = df_clean.drop(columns=['faster_lap_circuit_ever'])\n",
    "\n",
    "df_clean = df_clean.dropna(subset=['AvgFn'])\n",
    "# remove duplicate rows\n",
    "# df_clean = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.717762Z",
     "start_time": "2023-06-27T06:53:51.712702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "constructorId               0\ngrid                        0\nposition                    0\nlaps                        0\nnationality                 0\nround                       0\ncircuitId                   0\ncountry_circuit             0\nheight                      0\nnationality_constructors    0\npoints_season               0\nposition_season             0\nwins_season                 0\nage                         0\nweather_condition           0\nhumidity                    0\ntemperature                 0\nAvgGrid                     0\nAvgFn                       0\nwins_acc                    0\ndtype: int64"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect null values\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "['constructorId',\n 'grid',\n 'position',\n 'laps',\n 'nationality',\n 'round',\n 'circuitId',\n 'country_circuit',\n 'height',\n 'nationality_constructors',\n 'points_season',\n 'position_season',\n 'wins_season',\n 'age',\n 'weather_condition',\n 'humidity',\n 'temperature',\n 'AvgGrid',\n 'AvgFn',\n 'wins_acc']"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.720952Z",
     "start_time": "2023-06-27T06:53:51.716629Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.723039Z",
     "start_time": "2023-06-27T06:53:51.721146Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = df_clean.drop(columns=['position']), df_clean['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components='mle', svd_solver='full')\n",
    "X_pca = pca.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:53:51.843046Z",
     "start_time": "2023-06-27T06:53:47.860011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:54:11.960209Z",
     "start_time": "2023-06-27T06:53:51.793493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.599 (+/- 0.121)\n",
      "MAE: 14.181 (+/- 2.709)\n",
      "MSE: 458.098 (+/- 170.904)\n",
      "Explained Variance: 0.602 (+/- 0.113)\n",
      "Median Absolute Error: 9.020 (+/- 1.949)\n"
     ]
    }
   ],
   "source": [
    "# Randon Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "_ = EvaluatedClassifier(RandomForestRegressor(), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:54:17.954220Z",
     "start_time": "2023-06-27T06:54:11.960906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.598 (+/- 0.124)\n",
      "MAE: 14.190 (+/- 2.753)\n",
      "MSE: 458.825 (+/- 174.537)\n",
      "Explained Variance: 0.601 (+/- 0.116)\n",
      "Median Absolute Error: 9.060 (+/- 1.831)\n"
     ]
    }
   ],
   "source": [
    "_ = EvaluatedClassifier(RandomForestRegressor(n_jobs=-1), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.597 (+/- 0.126)\n",
      "MAE: 14.944 (+/- 2.006)\n",
      "MSE: 460.617 (+/- 180.710)\n",
      "Explained Variance: 0.599 (+/- 0.120)\n",
      "Median Absolute Error: 9.730 (+/- 1.366)\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "_ = EvaluatedClassifier(GradientBoostingRegressor(\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=100,\n",
    "), is_regression=True).fit_predict_cv(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:54:24.622231Z",
     "start_time": "2023-06-27T06:54:17.954915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.610 (+/- 0.136)\n",
      "MAE: 14.217 (+/- 2.381)\n",
      "MSE: 445.944 (+/- 190.628)\n",
      "Explained Variance: 0.612 (+/- 0.129)\n",
      "Median Absolute Error: 8.387 (+/- 1.268)\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "# finded through RandomizedSearchCV\n",
    "parms = {'validation_fraction': 0.1, 'tol': 0.0001, 'subsample': 1.0, 'random_state': 42, 'n_iter_no_change': 20,\n",
    "         'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 5,\n",
    "         'loss': 'huber', 'learning_rate': 0.1, 'criterion': 'friedman_mse', 'ccp_alpha': 0.1, 'alpha': 0.9}\n",
    "\n",
    "_ = EvaluatedClassifier(GradientBoostingRegressor(**parms), is_regression=True).fit_predict_cv(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:54:38.205053Z",
     "start_time": "2023-06-27T06:54:24.623874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:54:40.857077Z",
     "start_time": "2023-06-27T06:54:38.205974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.614 (+/- 0.148)\n",
      "MAE: 13.905 (+/- 2.747)\n",
      "MSE: 441.192 (+/- 201.549)\n",
      "Explained Variance: 0.617 (+/- 0.137)\n",
      "Median Absolute Error: 8.206 (+/- 1.877)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_eval = EvaluatedClassifier(XGBRegressor(\n",
    "    # n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    "    learning_rate=0.1,\n",
    "    # max_depth=8,\n",
    "), is_regression=True)\n",
    "\n",
    "_ = model_eval.fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.594 (+/- 0.117)\n",
      "MAE: 14.986 (+/- 2.678)\n",
      "MSE: 463.959 (+/- 165.778)\n",
      "Explained Variance: 0.596 (+/- 0.112)\n",
      "Median Absolute Error: 9.873 (+/- 1.754)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Finded through RandomizedSearchCV\n",
    "parms = {'subsample': 0.7, 'reg_lambda': 0.1, 'reg_alpha': 0.2, 'n_jobs': -1, 'n_estimators': 1500,\n",
    "         'min_child_weight': 7, 'max_depth': 8, 'learning_rate': 0.01, 'gamma': 0.2, 'colsample_bytree': 0.5}\n",
    "\n",
    "model_eval = EvaluatedClassifier(XGBRegressor(**parms), is_regression=True)\n",
    "_ = model_eval.fit_predict_cv(X_pca, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:58:28.590139Z",
     "start_time": "2023-06-27T06:57:36.608229Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.203 (+/- 0.274)\n",
      "MAE: 21.120 (+/- 3.749)\n",
      "MSE: 911.605 (+/- 390.605)\n",
      "Explained Variance: 0.301 (+/- 0.090)\n",
      "Median Absolute Error: 12.230 (+/- 1.066)\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "_ = EvaluatedClassifier(SVR(max_iter=-1), is_regression=True).fit_predict_cv(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T06:55:33.878348Z",
     "start_time": "2023-06-27T06:55:13.430804Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.248 (+/- 0.188)\n",
      "MAE: 22.861 (+/- 4.264)\n",
      "MSE: 858.001 (+/- 266.221)\n",
      "Explained Variance: 0.251 (+/- 0.180)\n",
      "Median Absolute Error: 17.465 (+/- 4.526)\n",
      "> Validação Cruzada (cv=10):\n",
      "R2: 0.549 (+/- 0.121)\n",
      "MAE: 14.994 (+/- 2.691)\n",
      "MSE: 514.886 (+/- 174.013)\n",
      "Explained Variance: 0.556 (+/- 0.112)\n",
      "Median Absolute Error: 8.471 (+/- 1.535)\n"
     ]
    }
   ],
   "source": [
    " # MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Finded through HalvingRandomSearchCV\n",
    "parms = {'solver': 'adam', 'momentum': 0.95, 'max_iter': 500, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive',\n",
    "         'hidden_layer_sizes': (100, 50), 'epsilon': 1e-06, 'beta_2': 0.9, 'beta_1': 0.9, 'batch_size': 32,\n",
    "         'alpha': 0.1, 'activation': 'tanh'}\n",
    "\n",
    "_ = EvaluatedClassifier(MLPRegressor(**parms), is_regression=True).fit_predict_cv(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T06:56:03.853866Z",
     "start_time": "2023-06-27T06:56:03.822326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export the model\n",
    "model_eval.save('../model/model_grid.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
